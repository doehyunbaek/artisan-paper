16:24:49 - artisan:INFO - util.py:385 - Logging into /home/doehyunbaek/artisan/logs/artisan-gpt5.1-8ee8/pythonic/table_2/072449-432283/artisan.log
16:24:49 - artisan:DEBUG - artisan.py:203 - Added docker privileged mode
16:24:49 - artisan:DEBUG - artisan.py:205 - Forwarded env var OPENAI_API_KEY
16:24:49 - artisan:DEBUG - artisan.py:207 - Forwarded env var MSWEA_SILENT_STARTUP
16:24:49 - artisan:DEBUG - artisan.py:210 - Added workspace volume mount: /home/doehyunbaek/artisan/logs/artisan-gpt5.1-8ee8/pythonic/table_2/072449-432283:/workspace:rw
16:24:49 - artisan:DEBUG - artisan.py:222 - Added docker socket volume mount: /var/run/docker.sock
16:24:49 - artisan:INFO - artisan.py:228 - Copied /tmp/tmpabgy6hhv.md -> /home/doehyunbaek/artisan/logs/artisan-gpt5.1-8ee8/pythonic/table_2/072449-432283/expected.md
16:24:49 - artisan:INFO - artisan.py:228 - Copied /home/doehyunbaek/artisan/evaluation/papers/obfuscated/pythonic_paper_2.md -> /home/doehyunbaek/artisan/logs/artisan-gpt5.1-8ee8/pythonic/table_2/072449-432283/paper.md
16:24:51 - artisan:INFO - artisan.py:145 - Running DefaultAgent
16:24:51 - artisan:DEBUG - artisan.py:61 - role: system, content:
You are a helpful assistant that can interact with a computer.

Your response must contain exactly ONE bash code block with ONE command (or commands connected with && or ||).
Include a THOUGHT section before your command where you explain your reasoning process.
Format your response as shown in <format_example>.

<format_example>
THOUGHT: Your reasoning and analysis here. Explain why you want to perform the action.

<mini_swe_agent_bash>
your_command_here
</mini_swe_agent_bash>
</format_example>

Failure to follow these rules will cause your response to be rejected.
16:24:51 - artisan:DEBUG - artisan.py:61 - role: user, content:
Please reproduce the results reported in Table 2 of the target paper.

<expected_table>
**Table 2: Number and percentage of correct/wrong tasks for functional constructs and their procedural alternatives**

| Construct | **Functional — Corr.** | **Functional — Wrong** | **Functional — % Corr.** | **Procedural — Corr.** | **Procedural — Wrong** | **Procedural — % Corr.** |
| --------- | ---------------------: | ---------------------: | -----------------------: | ---------------------: | ---------------------: | -----------------------: |
| Lambda    |                    ??? |                     ?? |                    ??.?? |                    ??? |                     ?? |                    ??.?? |
| Compr.    |                     ?? |                    ??? |                    ??.?? |                    ??? |                     ?? |                    ??.?? |
| MRF       |                     ?? |                    ??? |                    ??.?? |                     ?? |                    ??? |                    ??.?? |

</expected_table>

The same table is available at `/workspace/expected.md`.
The paper that the table is from is available at `/workspace/paper.md`.

### Available tools
- `artisan get`: Download and extract the artifact from the official URL.
- `artisan format --expected /workspace/expected.md --repro /workspace/repro.txt`: Render final tables.
- `artisan submit`: Submit your reproduction script for evaluation.
- `uvx --from csvkit in2csv`: Inspect spreadsheet contents.
- `uvx --from pymupdf4llm python -c 'import sys, pymupdf4llm as p; sys.stdout.write(p.to_markdown(sys.argv[1]))'`: Convert PDFs to Markdown for easier reading.

#### Example actions
THOUGHT: List the sheets inside the artifact workbook.

<mini_swe_agent_bash>
uvx --from csvkit in2csv -n result.xlsx
</mini_swe_agent_bash>

THOUGHT: Convert the "lambda" worksheet to CSV to analyze it.

<mini_swe_agent_bash>
uvx --from csvkit in2csv -s "lambda" result.xlsx
</mini_swe_agent_bash>

THOUGHT: Read the PDF as Markdown to look for reproduction steps.

<mini_swe_agent_bash>
uvx --from pymupdf4llm python -c 'import sys, pymupdf4llm as p; sys.stdout.write(p.to_markdown(sys.argv[1]))' results.pdf
</mini_swe_agent_bash>

---
## Workflow overview

This workflows MUST be done step-by-step.
IMPORTANT: You MUST NOT run multiple steps in a single bash code block.

1. **Download the artifact** from https://zenodo.org/records/10554377.
   - You MUST use`artisan get https://zenodo.org/records/10554377`.
2. **Read the README** to understand reproduction steps.
3. **Locate relevant commands** for Table 2:
   - `grep -in docker README.md`
   - `grep -in "Table 2" README.md`
4. **Execute the required commands** step-by-step:
   - Prefer Docker instructions from the README. Acquire images in the order `docker pull` → `docker load` → `docker import` → `docker build`.
   - Replace `docker run -it` with `docker run -d --init --entrypoint bash <image> -c 'sleep infinity'`.
   - Use `docker exec <container> /bin/bash --noprofile --norc -c "<your_command>"` for shell access.
   - Run `docker-compose` exactly as documented if present.
5. **Author the submission script** `repro_pythonic_table_2.sh` using the template below.

---
## Submission script template
<mini_swe_agent_bash>
cat > /workspace/repro_pythonic_table_2.sh <<'EOF'
#!/usr/bin/bash
# Section 1: Expected table
cat > /workspace/expected.md <<'EOTABLE'
**Table 2: Number and percentage of correct/wrong tasks for functional constructs and their procedural alternatives**

| Construct | **Functional — Corr.** | **Functional — Wrong** | **Functional — % Corr.** | **Procedural — Corr.** | **Procedural — Wrong** | **Procedural — % Corr.** |
| --------- | ---------------------: | ---------------------: | -----------------------: | ---------------------: | ---------------------: | -----------------------: |
| Lambda    |                    ??? |                     ?? |                    ??.?? |                    ??? |                     ?? |                    ??.?? |
| Compr.    |                     ?? |                    ??? |                    ??.?? |                    ??? |                     ?? |                    ??.?? |
| MRF       |                     ?? |                    ??? |                    ??.?? |                     ?? |                    ??? |                    ??.?? |

EOTABLE
# Section 2: Artifact download
<Commands to download the artifact>
artisan get https://zenodo.org/records/10554377
# Section 3: Reproduction commands (populate from reviewed steps)
<Commands to reproduce the table. They should output the reproduction results to /workspace/repro.txt>
# Section 4: Formatting and submission block
echo '<artisan_submit>'
<Commands to format the output table>
artisan format --expected /workspace/expected.md --repro /workspace/repro.txt
echo '</artisan_submit>'
EOF
chmod +x /workspace/repro_pythonic_table_2.sh
artisan submit /workspace/repro_pythonic_table_2.sh
</mini_swe_agent_bash>

---
## Important rules
- Perform only one logical step per command; avoid batching multiple workflow stages.
- Each command has an eight-hour timeout—plan accordingly.
- After verification succeeds, finish with `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT` as a standalone command; no further work is allowed afterward.
16:24:55 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: Start by downloading and unpacking the artifact from the provided Zenodo record so I can inspect its contents (especially the README) and later locate the data/commands needed to reproduce Table 2.

<mini_swe_agent_bash>
artisan get https://zenodo.org/records/10554377
</mini_swe_agent_bash>
16:25:05 - artisan:DEBUG - artisan.py:61 - role: user, content:
<returncode>0</returncode>
<output>

Downloading ICSE2024-funcConstructs-Artifacts.zip 0% (65536/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 1% (131072/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 2% (196608/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 3% (262144/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 4% (327680/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 5% (393216/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 6% (458752/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 7% (524288/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 8% (589824/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 9% (655360/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 10% (720896/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 11% (786432/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 12% (851968/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 13% (917504/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 14% (983040/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 15% (1048576/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 16% (1114112/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 16% (1179648/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 17% (1245184/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 18% (1310720/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 19% (1376256/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 20% (1441792/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 21% (1507328/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 22% (1572864/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 23% (1638400/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 24% (1703936/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 25% (1769472/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 26% (1835008/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 27% (1900544/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 28% (1966080/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 29% (2031616/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 30% (2097152/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 31% (2162688/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 32% (2228224/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 33% (2293760/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 33% (2359296/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 34% (2424832/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 35% (2490368/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 36% (2555904/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 37% (2621440/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 38% (2686976/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 39% (2752512/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 40% (2818048/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 41% (2883584/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 42% (2949120/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 43% (3014656/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 44% (3080192/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 45% (3145728/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 46% (3211264/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 47% (3276800/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 48% (3342336/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 49% (3407872/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 50% (3473408/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 50% (3538944/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 51% (3604480/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 52% (3670016/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 53% (3735552/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 54% (3801088/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 55% (3866624/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 56% (3932160/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 57% (3997696/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 58% (4063232/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 59% (4128768/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 60% (4194304/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 61% (4259840/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 62% (4325376/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 63% (4390912/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 64% (4456448/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 65% (4521984/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 66% (4587520/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 67% (4653056/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 67% (4718592/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 68% (4784128/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 69% (4849664/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 70% (4915200/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 71% (4980736/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 72% (5046272/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 73% (5111808/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 74% (5177344/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 75% (5242880/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 76% (5308416/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 77% (5373952/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 78% (5439488/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 79% (5505024/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 80% (5570560/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 81% (5636096/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 82% (5701632/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 83% (5767168/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 84% (5832704/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 84% (5898240/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 85% (5963776/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 86% (6029312/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 87% (6094848/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 88% (6160384/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 89% (6225920/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 90% (6291456/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 91% (6356992/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 92% (6422528/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 93% (6488064/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 94% (6553600/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 95% (6619136/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 96% (6684672/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 97% (6750208/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 98% (6815744/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 99% (6881280/6943661 bytes)
Downloading ICSE2024-funcConstructs-Artifacts.zip 100% (6943661/6943661 bytes)
Storing downloaded file into cache for URL: https://zenodo.org/api/records/10554377/files/ICSE2024-funcConstructs-Artifacts.zip/content

Copying ICSE2024-funcConstructs-Artifacts.zip -> /root/.cache/artisan/files/e6b2b6c6547d6a6c1ca4edcbdb1da8a9269178e6b2f4b97a8d497dae9286c26c/ICSE2024-funcConstructs-Artifacts.zip

Saved to ICSE2024-funcConstructs-Artifacts.zip (6943661 bytes)

README PATH: ICSE2024-funcConstructs-Artifacts/ICSE2024-funcConstructs-Artifacts/README.md

</output>
16:25:07 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: Inspect the README to understand the artifact structure and find the instructions needed to reproduce Table 2.

<mini_swe_agent_bash>
cat ICSE2024-funcConstructs-Artifacts/ICSE2024-funcConstructs-Artifacts/README.md
</mini_swe_agent_bash>
16:25:07 - artisan:DEBUG - artisan.py:61 - role: user, content:
<returncode>0</returncode>
<output>

# Replication Package for "_A Study on the Pythonic Functional Constructs' Understandability_" to appear at ICSE 2024

- **Authors**: Cyrine Zid, Fiorella Zampetti, Giuliano Antoniol, Massimiliano Di penta
- **Article Preprint:** [https://mdipenta.github.io/files/ICSE24_funcExperiment.pdf](https://mdipenta.github.io/files/ICSE24_funcExperiment.pdf)
- **Artifacts:** [https://doi.org/10.5281/zenodo.8191782](https://doi.org/10.5281/zenodo.8191782)
- **License**: [GPL V3.0](LICENSE.md)


This package contains folders and files with code and data used in the study described in the paper. In the following, we first provide all fields required for the submission, and then report a detailed description of all repository folders.

## Artifact Description
### Purpose
The artifact is about a controlled experiment aimed at investigating the extent to which Pythonic functional constructs have an impact on source code understandability. The artifact archive contains:

1. The material to allow replicating the study (see Section [Experimental-Material](#material))
2. Raw quantitative results, working datasets, and scripts to replicate the statistical analyses reported in the paper. Specifically, the executable part of the replication package reproduces figures and tables of the quantitative analysis (RQ1 and RQ2) of the paper starting from the working datasets.
3. Spreadsheets used for the qualitative analysis (RQ3). 

We apply for the following badges:

-  **Available and reusable**: because we provide all the material that can be used to replicate the experiment, but also to perform the statistical analyses and the qualitative analyses (spreadsheets, in this case)


### Provenance

- **Paper preprint link:** [https://mdipenta.github.io/files/ICSE24_funcExperiment.pdf](https://mdipenta.github.io/files/ICSE24_funcExperiment.pdf)
- **Artifacts:** [https://doi.org/10.5281/zenodo.8191782](https://doi.org/10.5281/zenodo.8191782)

### Data
Results have been obtained by conducting the controlled experiment involving [Prolific](https://www.prolific.com) workers as participants. Data collection and processing followed a protocol approved by the University ethical board. Note that all data enclosed in the artifact is completely anonymized and does not contain sensible information.

Further details about the provided dataset can be found in the Section [Results' directory and files](#results)


### Setup and Usage (for executable artifacts): 
See the Section [Scripts to reproduce the results, and instructions for running them](#scripts)




## [Experiment-Material/](Experiment-Material/)
<a id="material"></a>
Contains the material used for the experiment, and, specifically, the following subdirectories:

### [Google-Forms/](Experiment-Material/Google-Forms/)
Contains (as PDF documents) the questionnaires submitted to the ten experimental groups.

### [Task-Sources/](Experiment-Material/Task-Sources/)
Contains, for each experimental group (G-1...G-10), the sources used to produce the Google Forms, and, specifically:
- The cover letter (Letter.docx).
- A directory for each experimental task (Lambda 1, Lambda 2, Comp 1, Comp 2, MRF 1, MRF 2, Lambda Comparison, Comp Comparison, MRF Comparison). Each directory contains: (i) the exercise text (in both Word and .txt format), the source code snippet, and its .png image to be used in the form. **Note:** the "Comparison" tasks do not have any exercise as the purpose is always the same, i.e., to compare the (perceived) understandability of the snippets and return the results of the comparison. 

### [Code-Examples-Table1/](Experiment-Material/Code-Examples-Table1/)
Contains the source code snippets used as objects of the study (the same you can find under "Task-Sources/"), named as reported in Table 1.








## Results' directory and files
<a id="results"></a>

### [raw-responses/](raw-responses/)
Contains, as spreadsheets, the raw responses provided by the study participants through Google forms.

### [raw-results-RQ1/](raw-results-RQ1/)
Contains the raw results for RQ1. Specifically, the directory contains a subdirectory for each group (G1-G10). Each subdirectory contains:
- For each user (named using their Prolific  IDs, a directory containing, for each question (Q1-Q6) the produced python code (Qn.py) its output (QnR.txt) and its StdErr output (QnErr.txt).
- "expected-outputs/": A directory containing the expected outputs for each task (Qn.txt).

#### [working-results/RQ1-RQ2-files-for-statistical-analysis/](working-results/RQ1-RQ2-files-for-statistical-analysis/)
Contains three .csv files used as input for conducting the statistical analysis and drawing the graphs for addressing the first two research questions of the study. Specifically:

- [ConstructUsage.csv](working-results/RQ1-RQ2-files-for-statistical-analysis/ConstructUsage.csv) contains the declared frequency usage of the three functional constructs object of the study. This file is used to draw Figure 4. The file contains an entry for each participant, reporting the (text-coded) frequency of construct usage for Comprehension, Lambda, and MRF.

- [RQ1.csv](working-results/RQ1-RQ2-files-for-statistical-analysis/RQ1.csv) contains the collected data used for the mixed-effect logistic regression relating the use of functional constructs with the correctness of the change task, as well as the logistic regression relating the use of map/reduce/filter functions with the correctness of the change task. 
    The csv file contains an entry for each answer provided by each subject, and features the following columns:
    - *Group*: experimental group to which the participant is assigned
    - *User*: user ID
    - *Time*: task time in seconds
    - *Approvals*: number of approvals on previous tasks performed on Prolific
    - *Student*: whether the participant declared themselves as a student
    - *Section*: section of the questionnaire (lambda, comp, or mrf)
    - *Construct*: specific construct being presented (same as "Section" for lambda and comp, for mrf it says whether it is a map, reduce, or filter)
    - *Question*: question id, from Q1 to Q6, indicate the ordering of the question
    - *MainFactor*: main factor treatment for the given question - "f" for functional, "p" for procedural counterpart
    - *Outcome*: TRUE if the task was correctly performed, FALSE otherwise
    - *Complexity*: cyclomatic complexity of the construct (empty for mrf)
    - *UsageFrequency*: usage frequency of the given construct


- [RQ1Paired-RQ2.csv](working-results/RQ1-RQ2-files-for-statistical-analysis/RQ1Paired-RQ2.csv) contains the collected data used for the ordinal logistic regression of the relationship between the perceived ease of understanding of the functional constructs and (i) participants' usage frequency, and (ii) constructs' complexity (except for map/reduce/filter).
    The file features a row for each participant, and the columns are the following:
    
    - *Group*: experimental group to which the participant is assigned
    - *User*: user ID
    - *Time*: task time in seconds
    - *Approvals*: number of approvals on previous tasks performed on Prolific
    - *Student*: whether the participant declared themselves as a student
    - *LambdaF*: result for the change task related to a lambda construct
    - *LambdaP*: result for the change task related to the procedural counterpart of a lambda construct
    - *CompF*: result for the change task related to a comprehension construct
    - *CompP*: result for the change task related to the procedural counterpart of a comprehension construct
    - *MrfF*: result for the change task related to an MRF construct
    - *MrfP*: result for the change task related to the procedural counterpart of a MRF construct
    - *LambdaComp*: perceived understandability level for the comparison task (RQ2) between a lambda and its procedural counterpart
    - *CompComp*: perceived understandability level for the comparison task (RQ2) between a comprehension and its procedural counterpart
    - *MrfComp*: perceived understandability level for the comparison task (RQ2) between a MRF and its procedural counterpart
    - *LambdaCompCplx*: cyclomatic complexity of the lambda construct involved in the comparison task (RQ2)
    - *CompCompCplx*: cyclomatic complexity of the comprehension construct involved in the comparison task (RQ2)
    - *MrfCompType*: type of MRF construct (map, reduce, or filter) used in the comparison task (RQ2)
    - *LambdaUsageFrequency*: self-declared usage frequency on lambda constructs
    - *CompUsageFrequency*: self-declared usage frequency on comprehension constructs
    - *MrfUsageFrequency*: self-declared usage frequency on MRF constructs
    - *LambdaComparisonAssessment*: outcome of the manual assessment of the answer to the "check question" required for the lambda comparison ("yes" means valid, "no" means wrong, "moderate_chatgpt" and "extreme_chatgpt" are the results of GPTZero)
    - *CompComparisonAssessment*: as above, but for comprehension
    - *MrfComparisonAssessment*: as above, but for MRF
    

### [working-results/inter-rater-RQ3-files/](working-results/inter-rater-RQ3-files/)
This directory contains four .csv files used as input for computing the inter-rater agreement for the manual labeling used for addressing RQ3. Specifically, you will find one file for each functional construct, i.e., comprehension.csv, lambda.csv, and mrf.csv, and a different file used for highlighting the reasons why participants prefer to use the procedural paradigm, i.e., procedural.csv.


### [working-results/RQ2ManualValidation.csv](working-results/RQ2ManualValidation.csv)
This file contains the results of the manual validation being done to sanitize the answers provided by our participants used for addressing RQ2. Specifically, we coded the behaviour description using four different levels: (i) correct ("yes"), (ii) somewhat correct ("partial"), (iii) wrong ("no"), and (iv) automatically generated. The file features a row for each participant, and the columns are the following:

- *ID*: ID we used to refer the participant in the paper's qualitative analysis
- *Group*: experimental group to which the participant is assigned
- *ProlificID*: user ID
- *Comparison for lambda construct description*: answer provided by the user for the lambda comparison task
- *Final Classification*: our assessment of the lambda comparison answer
- *Comparison for comprehension description*: answer provided by the user for the comprehension comparison task
- *Final Classification*: our assessment of the comprehension comparison answer
- *Comparison for MRF description*: answer provided by the user for the MRF comparison task
- *Final Classification*: our assessment of the MRF comparison answer


### [working-results/RQ3ManualValidation.xlsx](working-results/RQ3ManualValidation.xlsx)
This file contains the results of the open coding applied to address our third research question. Specifically, you will find four sheets, one for each functional construct and one for the procedural paradigm. Each sheet reports the provided answers together with the categories assigned to them. 
Each sheet contains the following columns:

- *ID*: ID we used to refer the participant in the paper's qualitative analysis
- *Group*: experimental group to which the participant is assigned
- *ProlificID*: user ID (as in the tables from the quantitative analysis)    
- *<Question being asked>*:  question asked to the user
- *Final Classification*: The outcome of our categorization according to the taxonomy shown in Table 10.


## Scripts to reproduce the results and instructions for running them
<a id="scripts"></a>

### [FuncConstructs-Statistics.r](FuncConstructs-Statistics.r) 
This file contains an R script that you can reuse to re-run all the analyses conducted and discussed in the paper. 

### [FuncConstructs-Statistics.ipynb](FuncConstructs-Statistics.ipynb)
This file contains the code to re-execute all the analysis conducted in the paper as a Jupyter Notebook (using the R Kernel).

### [run-analysis.sh](run-analysis.sh)
This script can be used to run the R script `FuncConstructs-Statistics.r` using a Docker container (see Option 1 below) in Unix operating systems.

### [run-analysis.bat](run-analysis.bat)
This script can be used to run the R script `FuncConstructs-Statistics.r` using a Docker container (see Option 1 below) in Windows operating systems (power shell recommended).

### [run-jupyter-container.sh](run-jupyter-container.sh)
This script can be used to run a local Jupyter server (with R kernel and all required packages) from a Docker container (see Option 3 below) in Unix operating system.

### [run-jupyter-container.bat](run-jupyter-container.bat)
This script can be used to run a local Jupyter server (with R kernel and all required packages) from a Docker container (see Option 3 below) in Windows operating systems (power shell recommended).


### How to Run the scripts
There are four options to run the scripts. In all cases, one has first to open a shell terminal window (e.g., bash or sh in Unixes) in the replication package directory. For Windows, we suggest to use a Power Shell.

1. **Running the R script using Dockerized R installation**: this is the simplest option, and it simply requires a running Docker engine. In **Unix (MacOS, Linux)**, to produce the results, one has to run the shell script "run-analysis.sh" (e.g., by typing `sh run-analysis.sh` or simply `./run-analysis.sh` after making it executable).  In **Windows**, one has to run the script "run-analysis.bat" instead (by typing `.\run-analysis.bat`). This script (either .sh or .bat) will:
    - Pull a docker image named `mdipenta/rexp` which contains an R installation with all required packages.
    - Run R from the container created from the image and produce the paper's results under a directory named `results/`.
    
    - **Note:** An alternative would be to run everything from inside the container, after running it in interactive mode. To this aim, please execute the following commands:
          1. In **Unix**: `docker run -v${PWD}:/data --rm -ti --name shell mdipenta/rexp:latest bash` in **Windows**: `docker run -v %cd%:/data --rm -ti --name shell mdipenta/rexp:latest bash`    
          2. `cd data`
          3. `R --no-save < FuncConstructs-Statistics.r`
    After exiting the container, the "results" directory will be again populated with the study results.
        
2. **Running the R script from own R installation**: this option works if one has an R installation already (or wants to use an R installation) without relying on the Docker image. The steps to be followed are:
   - Uncomment the `install.packages(..)` instruction in the first lines of the script. This will allow for the installation of the required packages.
   - Just run, from the current directory, the script `FuncConstructs-Statistics.r`, using the command `Rscript FuncConstructs-Statistics.r` (making sure the directory containing Rscript is in your PATH, this should work fine in Unixes, it might require to modify the PATH environment variable in Windows). Should you experience problems with the first part of the script (installations), try to execute the `install.packages(..)` statement from your R GUI, and then run the script again.
   
3. **Using the Jupyter Notebook using a Dockerized Jupyter lab with R kernel**: this option allows for opening the Jupyter Notebook with all results without having to install Jupyter with the R kernel, nor all the required R packages. The steps required are:
    - Run the `./run-jupyter-container.sh` (**Unix**) or `.\run-jupyter-container.bat` (**Windows**). It will download the `mdipenta/myjupyter` image and run Jupyter lab from it.
    - Open a browser on [localhost:8888](http://localhost:8888) (or if it does not work, [127.0.0.1:8888)](http://127.0.0.1:8888) and, when being asked for a password, type `docker`. 
    - From the Jupyter lab page, open the "FuncConstruct-Statistics.ipynb" notebook, and (if you wish) re-run it, or simply browse its results. Note: differently from options 1 and 2, results are not saved, but just displayed in the notebook.
    
4. **Using the Jupyter Notebook from your installation**: this is similar to Option 3, but it can work if you have already Jupyter lab installed, with the R kernel enabled (for details see: [https://github.com/IRkernel/IRkernel](https://github.com/IRkernel/IRkernel)). The steps to follow are:
    - Run jupyter lab (e.g., jupyter lab from the command line) and open it on a webpage.
    - Open the `FuncConstruct-Statistics.ipynb` notebook.
    - If you want to re-execute it, uncomment the `install.packages()` line.
    - Re-run it (if you wish).
    

### The output
If using Option 1 or 2, the `results` directory will contain the following files:

- **Figures 4 and 5** as in the paper.
- **Tables 2-9** as in the paper in various formats (csv, tex, and for Tables 3-5 also .txt). Some notes: The diagnostics (top part, up to "Fixed effects") for Tables 3-5 are shown in the .txt files only. However, these files do not report the "OR" columns that correspond to exp(Estimate). This is because the .txt file contains the statistics dump which does not include the ORs. The .csv and .tex tables report the Fixed effects as shown in the paper, including the ORs. 
- **rq1-rq2-correlation** (.tex and .csv) contains the correlation analysis between RQ1 and RQ2 results as discussed in the "Threats to construct validity" (Section 6).
- **rq3-inter-rater** (.tex and .csv) contains the results of the inter-rater agreements analysis discussed in Section 3.6.
</output>
16:25:10 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: Search the README for any Docker-related instructions so I know how to correctly run the R analysis within a container for reproducing the tables.

<mini_swe_agent_bash>
grep -in docker ICSE2024-funcConstructs-Artifacts/ICSE2024-funcConstructs-Artifacts/README.md
</mini_swe_agent_bash>
16:25:10 - artisan:DEBUG - artisan.py:61 - role: user, content:
<returncode>0</returncode>
<output>
163:This script can be used to run the R script `FuncConstructs-Statistics.r` using a Docker container (see Option 1 below) in Unix operating systems.
166:This script can be used to run the R script `FuncConstructs-Statistics.r` using a Docker container (see Option 1 below) in Windows operating systems (power shell recommended).
169:This script can be used to run a local Jupyter server (with R kernel and all required packages) from a Docker container (see Option 3 below) in Unix operating system.
172:This script can be used to run a local Jupyter server (with R kernel and all required packages) from a Docker container (see Option 3 below) in Windows operating systems (power shell recommended).
178:1. **Running the R script using Dockerized R installation**: this is the simplest option, and it simply requires a running Docker engine. In **Unix (MacOS, Linux)**, to produce the results, one has to run the shell script "run-analysis.sh" (e.g., by typing `sh run-analysis.sh` or simply `./run-analysis.sh` after making it executable).  In **Windows**, one has to run the script "run-analysis.bat" instead (by typing `.\run-analysis.bat`). This script (either .sh or .bat) will:
179:    - Pull a docker image named `mdipenta/rexp` which contains an R installation with all required packages.
183:          1. In **Unix**: `docker run -v${PWD}:/data --rm -ti --name shell mdipenta/rexp:latest bash` in **Windows**: `docker run -v %cd%:/data --rm -ti --name shell mdipenta/rexp:latest bash`    
188:2. **Running the R script from own R installation**: this option works if one has an R installation already (or wants to use an R installation) without relying on the Docker image. The steps to be followed are:
192:3. **Using the Jupyter Notebook using a Dockerized Jupyter lab with R kernel**: this option allows for opening the Jupyter Notebook with all results without having to install Jupyter with the R kernel, nor all the required R packages. The steps required are:
194:    - Open a browser on [localhost:8888](http://localhost:8888) (or if it does not work, [127.0.0.1:8888)](http://127.0.0.1:8888) and, when being asked for a password, type `docker`. 
</output>
16:25:12 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: Locate any explicit mention of “Table 2” in the README to see if there are special instructions or file paths for reproducing that specific table.

<mini_swe_agent_bash>
grep -in "Table 2" ICSE2024-funcConstructs-Artifacts/ICSE2024-funcConstructs-Artifacts/README.md
</mini_swe_agent_bash>
16:25:12 - artisan:DEBUG - artisan.py:61 - role: user, content:
<returncode>1</returncode>
<output>
</output>
16:25:16 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: Inspect the `run-analysis.sh` script to see how it uses Docker and what commands it runs, so I can adapt them according to the given docker-run instructions and then reproduce the tables.

<mini_swe_agent_bash>
cat ICSE2024-funcConstructs-Artifacts/ICSE2024-funcConstructs-Artifacts/run-analysis.sh
</mini_swe_agent_bash>
16:25:16 - artisan:DEBUG - artisan.py:61 - role: user, content:
<returncode>0</returncode>
<output>
#! /bin/sh
cat FuncConstructs-Statistics.r | docker run --workdir /data -v${PWD}:/data --rm -i mdipenta/rexp R --no-save

</output>
16:25:25 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: Pull the required Docker image (`mdipenta/rexp`) specified by the README so I can later start a container and run the R analysis inside it.

<mini_swe_agent_bash>
docker pull mdipenta/rexp:latest
</mini_swe_agent_bash>
16:25:54 - artisan:DEBUG - artisan.py:61 - role: user, content:
<returncode>0</returncode>
<output>
latest: Pulling from mdipenta/rexp
2be50d1418f6: Pulling fs layer
bf17b7b52429: Pulling fs layer
4ba60adf7193: Pulling fs layer
9757002524d9: Pulling fs layer
e56b61288bd2: Pulling fs layer
3cdf2a03cf15: Pulling fs layer
0376bc1ffa66: Pulling fs layer
41a23af8523c: Pulling fs layer
9757002524d9: Waiting
e56b61288bd2: Waiting
3cdf2a03cf15: Waiting
0376bc1ffa66: Waiting
41a23af8523c: Waiting
bf17b7b52429: Verifying Checksum
bf17b7b52429: Download complete
9757002524d9: Download complete
e56b61288bd2: Verifying Checksum
e56b61288bd2: Download complete
4ba60adf7193: Verifying Checksum
4ba60adf7193: Download complete
2be50d1418f6: Verifying Checksum
2be50d1418f6: Download complete
41a23af8523c: Download complete
0376bc1ffa66: Verifying Checksum
0376bc1ffa66: Download complete
3cdf2a03cf15: Verifying Checksum
3cdf2a03cf15: Download complete
2be50d1418f6: Pull complete
bf17b7b52429: Pull complete
4ba60adf7193: Pull complete
9757002524d9: Pull complete
e56b61288bd2: Pull complete
3cdf2a03cf15: Pull complete
0376bc1ffa66: Pull complete
41a23af8523c: Pull complete
Digest: sha256:410e0a76cdd1d0a167f4a72c23a5cfa86a3d69731bd15c933004629cc3c9e6c6
Status: Downloaded newer image for mdipenta/rexp:latest
docker.io/mdipenta/rexp:latest
</output>
16:26:03 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: Start a long-running Docker container with the R environment, mounting the replication package directory so I can later exec into it to run the R script that generates the tables.

<mini_swe_agent_bash>
cd ICSE2024-funcConstructs-Artifacts/ICSE2024-funcConstructs-Artifacts && docker run -d --init --entrypoint bash --name func_rexp -v${PWD}:/data mdipenta/rexp:latest -c 'sleep infinity'
</mini_swe_agent_bash>
16:26:07 - artisan:DEBUG - artisan.py:61 - role: user, content:
<returncode>0</returncode>
<output>
663ee7047162028058ea5dbe76f1c39a37480209ce7fe23ced91d81762c117d9
</output>
16:26:10 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: Execute the R analysis script inside the running Docker container so that it produces all result tables (including Table 2) under the `results/` directory.

<mini_swe_agent_bash>
docker exec func_rexp /bin/bash --noprofile --norc -c "cd /data && R --no-save < FuncConstructs-Statistics.r"
</mini_swe_agent_bash>
16:26:12 - artisan:DEBUG - artisan.py:61 - role: user, content:
<returncode>0</returncode>
<output>

R version 4.3.2 (2023-10-31) -- "Eye Holes"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # Uncomment the following line to run this script from own R installation
> #install.packages(c("likert", "parameters", "reshape", "lme4","xtable","exact2x2","MASS","irr"))
> 
> library(likert)
Loading required package: ggplot2
Loading required package: xtable
> library(parameters)

Attaching package: ‘parameters’

The following object is masked from ‘package:xtable’:

    display

> library(reshape)
> library(lme4)
Loading required package: Matrix

Attaching package: ‘Matrix’

The following object is masked from ‘package:reshape’:

    expand

> library(xtable)
> library(exact2x2)
Loading required package: exactci
Loading required package: ssanv
Loading required package: testthat
> library(MASS)
> library(irr)
Loading required package: lpSolve
> 
> 
> inputDir="working-results//RQ1-RQ2-files-for-statistical-analysis"
> outputDir="results"
> irrDir="working-results//inter-rater-RQ3-files"
> 
> # Creates the output directory
> dir.create(outputDir)
Warning message:
In dir.create(outputDir) : 'results' already exists
> 
> # Writes a data frame into a CSV file
> toCSV<-function(data,fileName){
+     outFile=paste(outputDir,fileName,sep="//")
+     write.csv(data,file=outFile,quote=FALSE,row.names=FALSE)
+ }
> 
> # Writes a data object into a textual file
> toTxt<-function(data,fileName){
+     outFile=paste(outputDir,fileName,sep="//")
+     capture.output(
+         print(data),
+         file=outFile)
+ }
> 
> # Writes a data frame into a LaTex file, creating a table with a label and caption
> toLaTex<-function(data,fileName,label,caption){
+     outFileLatex=paste(outputDir,fileName,sep="//")
+     capture.output(
+         print(xtable(data,digits=3,label=label,caption=caption)),
+         file=outFileLatex)
+ }
> 
> ##############################
> # DEMOGRAPHICS
> ##############################
> 
> ### Likert Plot of constructs' usage (Figure 4)
> 
> t2<-read.csv(paste(inputDir,"ConstructUsage.csv",sep="//"))
> t2<-subset(t2,t2$Comprehension!="Never" | t2$Lambda!="Never" | t2$MRF!="Never")
> mylevels <- c('Never', 'Less than 25%', 'Between 25% and 75%', 'More than 75%')
> s2 <- as.data.frame(lapply(t2,function(x) {factor(x,levels=mylevels)}))
> 
> 
> l=likert(s2)
> par(mar = c(0, 0, 0, 0)) 
> pdf(file=paste(outputDir,"Figure-4-ConstructUsage.pdf",sep="//"),width=10,height=3)
> p<-plot(l,text.size=4,group.order=c("Lambda","Comprehension","MRF"))
> p+theme(axis.title.x=element_text(size = 16),
+         axis.text.x=element_text(size = 14),
+         axis.text.y=element_text(size = 14),
+         text=element_text(size = 14),
+         legend.title=element_text(size = 14),
+         legend.text=element_text(size = 14))
> dev.off()
pdf 
  2 
> 
> ##########################################
> # RQ1 - Descriptive statistics (Table 2)
> ##########################################
> t<-read.csv(paste(inputDir,"RQ1.csv",sep="//"))
> sections<-c("lambda","comp","mrf")
> res<-list(Construct=c(),Ftrue=c(),Ffalse=c(),Fperc=c(),Ptrue=c(),Pfalse=c(),Pperc=c())
> for(section in sections)
+ {
+   tsub<-subset(t,t$Section==section)
+   tt<-table(tsub$Outcome,tsub$MainFactor)
+   res$Construct=c(res$Construct,section)
+   
+   res$Ftrue=c(res$Ftrue,tt[2,1])
+   res$Ffalse=c(res$Ffalse,tt[1,1])
+   res$Fperc=c(res$Fperc,100*tt[2,1]/(tt[1,1]+tt[2,1]))
+   
+   res$Ptrue=c(res$Ptrue,tt[2,2])
+   res$Pfalse=c(res$Pfalse,tt[1,2])
+   res$Pperc=c(res$Pperc,100*tt[2,2]/(tt[1,2]+tt[2,2]))
+ }
> res=data.frame(res)
> res
  Construct Ftrue Ffalse    Fperc Ptrue Pfalse    Pperc
1    lambda   112     98 53.33333   115     95 54.76190
2      comp    99    111 47.14286   114     96 54.28571
3       mrf    80    130 38.09524    85    125 40.47619
> 
> outFile=paste(outputDir,"Table-2-descriptive.csv",sep="//")
> toCSV(res,"Table-2-descriptive.csv")
> toLaTex(res,"Table-2-descriptive.tex","tab:descr","Number and percentage of correct/wrong tasks for functional constructs and their procedural alternatives")
> 
> 
> 
> 
> ############################################################
> # RQ1 - Generalized linear models for different constructs
> ############################################################
> 
> 
> # Add 1 offset to Complexity as in the files it starts from 0
> t$Complexity=t$Complexity+1
> 
> print("LAMBDA:")
[1] "LAMBDA:"
> tLambda<-subset(t,t$Section=="lambda" & t$UsageFrequency>1)
> tLambda=droplevels(tLambda)
> attach(tLambda)
> 
> model<-glmer(Outcome~MainFactor*Complexity+UsageFrequency+Approvals+Student+(1|User),family="binomial",data=tLambda,control=glmerControl(optimizer="nloptwrap",calc.derivs=FALSE,optCtrl=list(maxfun=2e6)))
> smod=summary(model)
> smod$coefficients[,4]=p.adjust(smod$coefficients[,4],method="BH")
> mc=smod$coefficients
> OR=exp(mc[,1])
> coeffTable<-cbind(OR,mc)
> #pvalues=coeffTable[,5]
> #padjusted=p.adjust(pvalues,method="BH")
> #coeffTable[,5]=padjusted
> toTxt(smod,"Table-3-RQ1-lambda.txt")
> toCSV(coeffTable,"Table-3-RQ1-lambda-coeff.txt")
> toLaTex(coeffTable,"Table-3-RQ1-lambda-coeff.tex","tab:rq1lambda","RQ$_1$: Mixed-effect logistic regression relating the use of lambdas with the correctness of the change task")
> 
> 
> print("COMPREHENSION:")
[1] "COMPREHENSION:"
> tComp=subset(t,t$Section=="comp" & t$UsageFrequency>1)
> tComp=droplevels(tComp)
> attach(tComp)
The following objects are masked from tLambda:

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

> model<-glmer(Outcome~MainFactor*Complexity+UsageFrequency+Approvals+Student+(1|User),data=tComp,family="binomial",control=glmerControl(optimizer="nloptwrap",calc.derivs=FALSE,optCtrl=list(maxfun=2e6)))
> smod=summary(model)
> smod$coefficients[,4]=p.adjust(smod$coefficients[,4],method="BH")
> mc=smod$coefficients
> OR=exp(mc[,1])
> coeffTable<-cbind(OR,mc)
> #pvalues=coeffTable[,5]
> #padjusted=p.adjust(pvalues,method="BH")
> #coeffTable[,5]=padjusted
> toTxt(smod,"Table-4-RQ1-comp.txt")
> toCSV(coeffTable,"Table-4-RQ1-comp-coeff.txt")
> toLaTex(coeffTable,"Table-4-RQ1-comp-coeff.tex","tab:rq1comp","RQ$_1$: Mixed-effect logistic regression relating the use of comprehensions with the correctness of the change task")
> 
> 
> 
> print("MRF:")
[1] "MRF:"
> tMrf=subset(t,t$Section=="mrf" & t$UsageFrequency>1)
> tMrf=droplevels(tMrf)
> attach(tMrf)
The following objects are masked from tComp:

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tLambda:

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

> model<-glmer(Outcome~MainFactor+UsageFrequency+Approvals+Student+(1|User),data=tMrf,family="binomial",control=glmerControl(optimizer="nloptwrap",calc.derivs=FALSE,optCtrl=list(maxfun=2e6)))
> smod=summary(model)
> mc=smod$coefficients
> smod$coefficients[,4]=p.adjust(smod$coefficients[,4],method="BH")
> OR=exp(mc[,1])
> coeffTable<-cbind(OR,mc)
> #pvalues=coeffTable[,5]
> #padjusted=p.adjust(pvalues,method="BH")
> #coeffTable[,5]=padjusted
> toTxt(smod,"Table-5-RQ1-mrf.txt")
> toCSV(coeffTable,"Table-5-RQ1-mrf-coeff.txt")
> toLaTex(coeffTable,"Table-5-RQ1-mrf-coeff.tex","tab:rq1mrf","RQ$_1$: Mixed-effect logistic regression relating the use of MRF with the correctness of the change task")
> 
> 
> print("MAP:")
[1] "MAP:"
> tMrf=subset(t,t$Section=="mrf" & t$Construct=="map" & t$UsageFrequency>1)
> tMrf=droplevels(tMrf)
> attach(tMrf)
The following objects are masked from tMrf (pos = 3):

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tComp:

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tLambda:

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

> model<-glm(Outcome~MainFactor+UsageFrequency+Approvals+Student,data=tMrf,family="binomial")
> smod=summary(model)
> mc=smod$coefficients
> pvalues=mc[,4]
> padjusted=p.adjust(pvalues,method="BH")
> mc[,4]=padjusted
> toCSV(mc,"Table-6-RQ1-map.csv")
> caption=paste("RQ$_1$: Logistic regression relating the use of map with the correctness of the change task (AIC=",round(model$aic),")",sep="")
> toLaTex(mc,"Table-6-RQ1-map.tex","tab:rq1map",caption)
> 
> 
> print("REDUCE:")
[1] "REDUCE:"
> tMrf=subset(t,t$Section=="mrf" & t$Construct=="reduce" & t$UsageFrequency>1)
> tMrf=droplevels(tMrf)
> attach(tMrf)
The following objects are masked from tMrf (pos = 3):

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tMrf (pos = 4):

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tComp:

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tLambda:

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

> model<-glm(Outcome~MainFactor+UsageFrequency+Approvals+Student,family="binomial")
> smod=summary(model)
> mc=smod$coefficients
> pvalues=mc[,4]
> padjusted=p.adjust(pvalues,method="BH")
> mc[,4]=padjusted
> toCSV(mc,"Table-7-RQ1-reduce.csv")
> caption=paste("RQ$_1$: Logistic regression relating the use of reduce with the correctness of the change task (AIC=",round(model$aic),")",sep="")
> toLaTex(mc,"Table-7-RQ1-reduce.tex","tab:rq1reduce",caption)
> 
> 
> 
> print("FILTER:")
[1] "FILTER:"
> tMrf=subset(t,t$Section=="mrf" & t$Construct=="filter" & t$UsageFrequency>1)
> tMrf=droplevels(tMrf)
> attach(tMrf)
The following objects are masked from tMrf (pos = 3):

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tMrf (pos = 4):

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tMrf (pos = 5):

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tComp:

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

The following objects are masked from tLambda:

    Approvals, Complexity, Construct, Group, MainFactor, Outcome,
    Question, Section, Student, Time, UsageFrequency, User

> model<-glm(Outcome~MainFactor+UsageFrequency+Approvals+Student,family="binomial")
> smod=summary(model)
> mc=smod$coefficients
> pvalues=mc[,4]
> padjusted=p.adjust(pvalues,method="BH")
> mc[,4]=padjusted
> toCSV(mc,"Table-8-RQ1-filter.csv")
> caption=paste("RQ$_1$: Logistic regression relating the use of filter with the correctness of the change task (AIC=",round(model$aic),")",sep="")
> toLaTex(mc,"Table-8-RQ1-filter.tex","tab:rq1filter",caption)
> 
> 
> 
> ##############################
> # RQ2
> ##############################
> 
> # Reads the dataset
> cmp<-read.csv(paste(inputDir,"RQ1Paired-RQ2.csv",sep="//"))
> 
> # Prepares the dataset
> clambda=subset(cmp,cmp$LambdaUsageFrequency>1 & cmp$LambdaComparisonAssessment!="extreme_chatgpt" & cmp$LambdaComparisonAssessment!="no",select=c(LambdaComp))
> clambda[,1]=as.factor(clambda[,1])
> ccomp=subset(cmp,cmp$CompUsageFrequency>1 & cmp$CompComparisonAssessment!="extreme_chatgpt" & cmp$CompComparisonAssessment!="no",select=c(CompComp))
> 
> ccomp[,1]=as.factor(ccomp[,1])
> cmrf=subset(cmp,cmp$MrfUsageFrequency>1 & cmp$MrfComparisonAssessment!="extreme_chatgpt" & cmp$MrfComparisonAssessment!="no",select=c(MrfComp))
> cmrf[,1]=as.factor(cmrf[,1])
> cmap=subset(cmp,cmp$MrfUsageFrequency>1 & cmp$MrfCompType=="map" & cmp$MrfComparisonAssessment!="extreme_chatgpt" & cmp$MrfComparisonAssessment!="no",select=c(MrfComp))
> cmap[,1]=as.factor(cmap[,1])
> creduce=subset(cmp,cmp$MrfUsageFrequency>1 & cmp$MrfCompType=="reduce" & cmp$MrfComparisonAssessment!="extreme_chatgpt" & cmp$MrfComparisonAssessment!="no",select=c(MrfComp))
> creduce[,1]=as.factor(creduce[,1])
> cfilter=subset(cmp,cmp$MrfUsageFrequency>1 & cmp$MrfCompType=="filter" & cmp$MrfComparisonAssessment!="extreme_chatgpt" & cmp$MrfComparisonAssessment!="no",select=c(MrfComp))
> cfilter[,1]=as.factor(cfilter[,1])
> 
> lenmax=max(c(nrow(clambda),nrow(ccomp),nrow(cmrf)))
> col_lambda=c(clambda[,1],rep(NA,lenmax-nrow(clambda)))
> col_comp=c(ccomp[,1],rep(NA,lenmax-nrow(ccomp)))
> col_mrf=c(cmrf[,1],rep(NA,lenmax-nrow(cmrf)))
> col_map=c(cmap[,1],rep(NA,lenmax-nrow(cmap)))
> col_reduce=c(creduce[,1],rep(NA,lenmax-nrow(creduce)))
> col_filter=c(cfilter[,1],rep(NA,lenmax-nrow(cfilter)))
> 
> newdf=data.frame(Lambda=as.factor(col_lambda),Comprehension=as.factor(col_comp),
+                  MRF=as.factor(col_mrf),Map=as.factor(col_map),
+                  Reduce=as.factor(col_reduce),Filter=as.factor(col_filter))
> 
> 
> # Creates the Likert plot
> l=likert(newdf)
> 
> pdf(file=paste(outputDir,"Figure-5-RQ2-Likert.pdf",sep="//"),width=10,height=3)
> p<-plot(l,text.size=4,group.order=c("Lambda","Comprehension","MRF","Map","Reduce","Filter"))
> p+theme(axis.title.x=element_text(size = 14),
+         axis.text.x=element_text(size = 12),
+         axis.text.y=element_text(size = 12),
+         text=element_text(size = 12),
+         legend.title=element_text(size = 12),
+         legend.text=element_text(size = 12))
> dev.off()
pdf 
  2 
> 
> ################################################
> # RQ2 - Statistics (ordinal logistic regression)
> ################################################
> 
> ## Lambda
> clambda=subset(cmp,cmp$LambdaUsageFrequency>1 & cmp$LambdaComparisonAssessment!="extreme_chatgpt" & cmp$LambdaComparisonAssessment!="no")
> model<-polr(as.factor(LambdaComp)~LambdaUsageFrequency+LambdaCompCplx,data=clambda,Hess=T)
> summary(model)
Call:
polr(formula = as.factor(LambdaComp) ~ LambdaUsageFrequency + 
    LambdaCompCplx, data = clambda, Hess = T)

Coefficients:
                       Value Std. Error t value
LambdaUsageFrequency  0.8302     0.3136  2.6473
LambdaCompCplx       -0.1324     0.1811 -0.7308

Intercepts:
    Value   Std. Error t value
1|2  1.6143  0.8068     2.0009
2|3  3.4802  0.8620     4.0375
3|4  4.5905  0.9227     4.9751
4|5  6.0351  1.1102     5.4360

Residual Deviance: 292.1506 
AIC: 304.1506 
> coeffs <- coef(summary(model))
> p <- pnorm(abs(coeffs[, "t value"]), lower.tail = FALSE) * 2
> OR<-exp(coeffs[,"Value"])
> tab<-cbind(OR=OR,coeffs, "p value" = round(p,3))
> tab=tab[1:2,]
> tab[,5]=p.adjust(tab[,5],method="BH")
> toCSV(tab,"Table-9-rq2-lambda.csv")
> toLaTex(tab,"Table-9-rq2-lambda.tex","tab:ordinal","RQ$_2$: Ordinal logistic regression results of the relationship between perceived understandability of the functional constructs and (i) participants' usage frequency, and (ii) constructs' complexity (except for MRF)")
>        
> # Comprehension
> ccomp=subset(cmp,cmp$CompUsageFrequency>1 & cmp$CompComparisonAssessment!="extreme_chatgpt" & cmp$CompComparisonAssessment!="no")
> cmp$CompCompCplx=cmp$CompCompCplx+1
> model<-polr(as.factor(CompComp)~CompUsageFrequency+CompCompCplx,data=ccomp,Hess=T)
> summary(model)
Call:
polr(formula = as.factor(CompComp) ~ CompUsageFrequency + CompCompCplx, 
    data = ccomp, Hess = T)

Coefficients:
                     Value Std. Error t value
CompUsageFrequency  0.4010     0.2178   1.841
CompCompCplx       -0.2566     0.1130  -2.270

Intercepts:
    Value   Std. Error t value
1|2 -0.5266  0.6611    -0.7965
2|3  0.8886  0.6621     1.3421
3|4  1.5550  0.6720     2.3141
4|5  2.7727  0.7056     3.9295

Residual Deviance: 499.1074 
AIC: 511.1074 
> coeffs <- coef(summary(model))
> p <- pnorm(abs(coeffs[, "t value"]), lower.tail = FALSE) * 2
> OR<-exp(coeffs[,"Value"])
> tab<-cbind(OR=OR,coeffs, "p value" = round(p,3))
> tab=tab[1:2,]
> tab[,5]=p.adjust(tab[,5],method="BH")
> toCSV(tab,"Table-9-rq2-comp.csv")
> toLaTex(tab,"Table-9-rq2-comp.tex","tab:ordinal","RQ$_2$: Ordinal logistic regression results of the relationship between perceived understandability of the functional constructs and (i) participants' usage frequency, and (ii) constructs' complexity (except for MRF)")
> 
> # MRF
> cmrf=subset(cmp,cmp$MrfUsageFrequency>1 & cmp$MrfComparisonAssessment!="extreme_chatgpt" & cmp$MrfComparisonAssessment!="no")
> model<-polr(as.factor(MrfComp)~MrfUsageFrequency,data=cmrf,Hess=T)
> summary(model)
Call:
polr(formula = as.factor(MrfComp) ~ MrfUsageFrequency, data = cmrf, 
    Hess = T)

Coefficients:
                  Value Std. Error t value
MrfUsageFrequency 0.581      0.252   2.305

Intercepts:
    Value  Std. Error t value
1|2 0.7200 0.6357     1.1325 
2|3 2.1826 0.6620     3.2970 
3|4 2.9651 0.6850     4.3283 
4|5 4.0694 0.7388     5.5080 

Residual Deviance: 402.0062 
AIC: 412.0062 
> coeffs <- coef(summary(model))
> p <- pnorm(abs(coeffs[, "t value"]), lower.tail = FALSE) * 2
> OR<-exp(coeffs[,"Value"])
> tab<-cbind(OR=OR,coeffs, "p value" = round(p,3))
> tab=tab[1:1,]
> toCSV(tab,"Table-9-rq2-mrf.csv")
> toLaTex(data.frame(t(tab)),"Table-9-rq2-mrf.tex","tab:ordinal","RQ$_2$: Ordinal logistic regression results of the relationship between perceived understandability of the functional constructs and (i) participants' usage frequency, and (ii) constructs' complexity (except for MRF)")
> 
> ############################################
> # Correlation between RQ1 and RQ2 results
> ############################################
> 
> tpaired<-read.csv(paste(inputDir,"RQ1Paired-RQ2.csv",sep="//"))
> types=c("Lambda","Comp","Mrf")
> 
> dep=list(Lambda=c(),Comp=c(),Mrf=c())
> for(i in 1:nrow(tpaired))
+ {
+   #typeconstruct="Lambda"
+   for(typeconstruct in types)
+   {
+     proc=paste(typeconstruct,"P",sep="")
+     func=paste(typeconstruct,"F",sep="")
+     if(tpaired[[proc]][i]==tpaired[[func]][i])
+     {
+       dep[[typeconstruct]]=c(dep[[typeconstruct]],0)
+     }
+     else if(tpaired[[proc]][i]==TRUE & tpaired[[func]][i]==FALSE)
+     {
+       dep[[typeconstruct]]=c(dep[[typeconstruct]],-1)
+     }
+     else
+     {
+       dep[[typeconstruct]]=c(dep[[typeconstruct]],1)
+     }
+   }
+ }
> dep=data.frame(dep)
> 
> types=c("Lambda","Comp","Mrf")
> 
> res=list(Construct=c(),p.value=c(),Tau=c())
> for(construct in types)
+ {
+     comparison=paste(construct,"Comp",sep="")
+     correlation=cor.test(dep[[construct]],tpaired[[comparison]],method="kendall")
+     res$Construct=c(res$Construct,construct)
+     res$p.value=c(res$p.value,correlation$p.value)
+     res$Tau=c(res$Tau,correlation$estimate)
+ }
> res=data.frame(res)
> toCSV(res,"rq1-rq2-correlation.csv")
> toLaTex(res,"rq1-rq2-correlation.tex","tab:rq1-rq2-correlation","RQ1-RQ2 correlation")
> 
> 
> 
> ##############################
> # RQ3 - INTER-RATER-AGREEMENT
> ##############################
> 
> res=list(Construct=c(),KrippAlpha=c())
> 
> #Lambdas
> df1<-read.csv(paste(irrDir,"lambda.csv",sep="//"),sep="\t",na.string="None")
> res$Construct=c(res$Construct,"Lambda")
> res$KrippAlpha=c(res$KrippAlpha, kripp.alpha(t(as.matrix(df1)))$value)
Warning message:
In kripp.alpha(t(as.matrix(df1))) : NAs introduced by coercion
> 
> #Comprehensions
> df2<-read.csv(paste(irrDir,"comprehension.csv",sep="//"),sep="\t",na.string="None")
> res$Construct=c(res$Construct,"Comprehension")
> res$KrippAlpha=c(res$KrippAlpha, kripp.alpha(t(as.matrix(df2)))$value)
> 
> #MRF
> df3<-read.csv(paste(irrDir,"mrf.csv",sep="//"),sep="\t",na.string="None")
Warning message:
In kripp.alpha(t(as.matrix(df2))) : NAs introduced by coercion
> res$Construct=c(res$Construct,"MRF")
> res$KrippAlpha=c(res$KrippAlpha, kripp.alpha(t(as.matrix(df3)))$value)
Warning message:
In kripp.alpha(t(as.matrix(df3))) : NAs introduced by coercion
> 
> #All constructs together
> df=rbind(df1,df2,df3)
> res$Construct=c(res$Construct,"All Functional")
> res$KrippAlpha=c(res$KrippAlpha, kripp.alpha(t(as.matrix(df)))$value)
Warning message:
In kripp.alpha(t(as.matrix(df))) : NAs introduced by coercion
> 
> #Procedural
> notusing<-read.csv(paste(irrDir,"procedural.csv",sep="//"),sep="\t",na.string="None")
> res$Construct=c(res$Construct,"Procedural")
> res$KrippAlpha=c(res$KrippAlpha, kripp.alpha(t(as.matrix(notusing)))$value)
Warning message:
In kripp.alpha(t(as.matrix(notusing))) : NAs introduced by coercion
> 
> res=data.frame(res)
> 
> toCSV(res,"rq3-inter-rater.csv")
> toLaTex(res,"rq3-inter-rater.tex","tab:rq3-inter-rater","RQ3 inter-rater agreements (Krippendorff's Alpha)")
> 
> 
> ################################################
> # Removes spurious Rplots.pdf due to ggplot2 bug
> ################################################
> if(file.exists("Rplots.pdf"))
+     {
+         file.remove("Rplots.pdf")
+     }
[1] TRUE
> 
</output>
16:27:48 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: I will create the `repro_pythonic_table_2.sh` script in `/workspace`, filling in Table 2 with the reproduced values (112/98/53.33 etc.), then have the script download the artifact, run the provided Docker-based R analysis via `run-analysis.sh`, extract the descriptive statistics for Table 2 from `results/Table-2-descriptive.csv`, render them into a Markdown table at `/workspace/repro.txt`, and finally call `artisan format` inside the required `<artisan_submit>` block. I’ll generate this script with a single shell command using `printf` and then submit it with `artisan submit`.

<mini_swe_agent_bash>
printf '%s\n' \
"#!/usr/bin/bash" \
"# Section 1: Expected table" \
"cat > /workspace/expected.md <<'EOTABLE'" \
"**Table 2: Number and percentage of correct/wrong tasks for functional constructs and their procedural alternatives**" \
"" \
"| Construct | **Functional — Corr.** | **Functional — Wrong** | **Functional — % Corr.** | **Procedural — Corr.** | **Procedural — Wrong** | **Procedural — % Corr.** |" \
"| --------- | ---------------------: | ---------------------: | -----------------------: | ---------------------: | ---------------------: | -----------------------: |" \
"| Lambda    |                    112 |                     98 |                    53.33 |                    115 |                     95 |                    54.76 |" \
"| Compr.    |                     99 |                    111 |                    47.14 |                    114 |                     96 |                    54.29 |" \
"| MRF       |                     80 |                    130 |                    38.10 |                     85 |                    125 |                    40.48 |" \
"" \
"EOTABLE" \
"# Section 2: Artifact download" \
"artisan get https://zenodo.org/records/10554377" \
"# Section 3: Reproduction commands (populate from reviewed steps)" \
"cd /workspace/ICSE2024-funcConstructs-Artifacts/ICSE2024-funcConstructs-Artifacts" \
"sh run-analysis.sh" \
"cat > /workspace/repro.txt <<'EOTABLE_REPRO'" \
"**Table 2: Number and percentage of correct/wrong tasks for functional constructs and their procedural alternatives**" \
"" \
"| Construct | **Functional — Corr.** | **Functional — Wrong** | **Functional — % Corr.** | **Procedural — Corr.** | **Procedural — Wrong** | **Procedural — % Corr.** |" \
"| --------- | ---------------------: | ---------------------: | -----------------------: | ---------------------: | ---------------------: | -----------------------: |" \
"EOTABLE_REPRO" \
"awk -F',' 'NR>1{if(\$1==\"lambda\") cname=\"Lambda\"; else if(\$1==\"comp\") cname=\"Compr.\"; else if(\$1==\"mrf\") cname=\"MRF\"; printf(\"| %-8s | %21d | %21d | %23.2f | %21d | %21d | %23.2f |\\\\n\", cname, \$2, \$3, \$4, \$5, \$6, \$7);}' results/Table-2-descriptive.csv >> /workspace/repro.txt" \
"# Section 4: Formatting and submission block" \
"echo '<artisan_submit>'" \
"artisan format --expected /workspace/expected.md --repro /workspace/repro.txt" \
"echo '</artisan_submit>'" \
> /workspace/repro_pythonic_table_2.sh && chmod +x /workspace/repro_pythonic_table_2.sh && artisan submit /workspace/repro_pythonic_table_2.sh
</mini_swe_agent_bash>
16:33:56 - artisan:DEBUG - artisan.py:61 - role: user, content:
<returncode>0</returncode>
<output>
Wrote format tool logs to /workspace/artisan-format.json
Wrote speedometer tool logs to /workspace/artisan-speedometer.json
Success: reproduce.sh output matches expected.md
Submitting to judge service at http://129.69.217.154:8000/submit...
</output>
16:33:58 - artisan:DEBUG - artisan.py:61 - role: assistant, content:
THOUGHT: The reproduction script has been submitted and validated; I will now signal task completion as required.

<mini_swe_agent_bash>
echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT
</mini_swe_agent_bash>
16:33:58 - artisan:INFO - artisan.py:84 - Validating submission: /home/doehyunbaek/artisan/logs/artisan-gpt5.1-8ee8/pythonic/table_2/072449-432283/repro_pythonic_table_2.sh
16:34:42 - artisan:DEBUG - artisan.py:61 - role: user, content:

16:34:42 - artisan:INFO - artisan.py:183 - Info status: Submitted
16:34:42 - artisan:INFO - artisan.py:184 - Result: 
